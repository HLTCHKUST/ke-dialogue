{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entity(entity):\n",
    "    return entity.lower().translate(str.maketrans('', '', string.punctuation + ' '))\n",
    "\n",
    "def align_prediction(predictions, reference_ids):\n",
    "    result = {ref_id: predictions[ref_id] for ref_id in reference_ids}\n",
    "    return result\n",
    "\n",
    "def remove_first_api_call(predictions):\n",
    "    result_dict = {}\n",
    "    for key, prediction in predictions.items():\n",
    "        new_prediction = []\n",
    "        is_skip = False\n",
    "        for turn in prediction:\n",
    "            if 'api_call' in turn['text'] and not is_skip:\n",
    "                is_skip = True\n",
    "            else:\n",
    "                new_prediction.append(turn)\n",
    "        result_dict[key] = new_prediction\n",
    "    return result_dict\n",
    "            \n",
    "def extract_goal_from_gold(golds, references, reference_ids):\n",
    "    # Build dialogue id to key string dict from references\n",
    "    id_to_key_dict = {}\n",
    "    for ref_id in reference_ids:\n",
    "        dialogue = references[int(ref_id)]\n",
    "        usr_dial = []\n",
    "        for turn in dialogue:\n",
    "            if turn['spk'] == 'USR':\n",
    "                usr_dial.append(turn['text'].translate(str.maketrans('', '', string.punctuation + ' ')))\n",
    "        id_to_key_dict[ref_id] = ''.join(usr_dial)\n",
    "        \n",
    "    # Build key string to constraint+goal dict from golds\n",
    "    key_to_goal_dict = {}\n",
    "    key_to_dial_dict = {}\n",
    "    for dialogue in golds:\n",
    "        usr_dial = []\n",
    "        for turn in dialogue['dial']:\n",
    "            usr_dial.append(turn['usr']['transcript'].lower().translate(str.maketrans('', '', string.punctuation + ' ')))\n",
    "        key_to_goal_dict[''.join(usr_dial)] = {'constraint': dialogue['goal']['constraints'], 'request':dialogue['goal']['request-slots']}\n",
    "        key_to_dial_dict[''.join(usr_dial)] = dialogue\n",
    "        \n",
    "    # Matching key between two dicts\n",
    "    id_to_goal_dict = {}\n",
    "    id_to_dial_dict = {}\n",
    "    for dial_id, str_key in id_to_key_dict.items():\n",
    "        id_to_goal_dict[dial_id] = key_to_goal_dict[str_key]\n",
    "        id_to_dial_dict[dial_id] = key_to_dial_dict[str_key]\n",
    "    \n",
    "    return id_to_goal_dict, id_to_dial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KBret\n",
    "kbret_json = json.load(open('../runs/CAMREST_flattenKB_False_kbpercentage_KBret/result.json','r'))\n",
    "kbret_ids = list(kbret_json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model prediction\n",
    "model_prediction_dict = {'KBret': kbret_json}\n",
    "for f in glob.glob('../runs/CAMREST_gpt2_graph_False_adj_False_edge_False_unilm_False_*/result.json'):\n",
    "    json_data = json.load(open(f))\n",
    "    \n",
    "    # Get Name\n",
    "    flattenKB = eval(f[f.index('flattenKB_') + len('flattenKB_'):].split('_')[0])\n",
    "    if flattenKB:\n",
    "        model_name = 'GPT2+KB'\n",
    "    else:\n",
    "        if 'kbpercentage_' in f:\n",
    "            kbpercentage = f[f.index('kbpercentage_') + len('kbpercentage_'):].split('_')[0]\n",
    "            model_name = f'GPT2+KA{kbpercentage}'\n",
    "        else:\n",
    "            raise ValueError('NO NO NO NO!!!!')\n",
    "        \n",
    "    # Preprocess\n",
    "    result_json = align_prediction(json_data, kbret_ids)\n",
    "    if model_name == 'GPT2+KB':\n",
    "        result_json = remove_first_api_call(result_json)\n",
    "        \n",
    "    # Push to buffer\n",
    "    model_prediction_dict[model_name] = result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load human prediction\n",
    "test_file = open('../data/CamRest/test.txt','r')\n",
    "\n",
    "human_json = {}\n",
    "sys_utterances = []\n",
    "for line in test_file:\n",
    "    if line == \"\\n\":\n",
    "        # Push to buffer\n",
    "        human_json[str(len(human_json))] = sys_utterances\n",
    "        \n",
    "        # Reinit variable\n",
    "        sys_utterances = []\n",
    "    else:\n",
    "        _, line = line.replace(\"\\n\",\"\").split(' ', 1)\n",
    "        if \"\\t\" in line:            \n",
    "            _, syst = line.split(\"\\t\")\n",
    "            if 'api_call' not in syst:\n",
    "                sys_utterances.append({'spk':'SYS','text':syst})       \n",
    "if len(sys_utterances) > 0:\n",
    "    # Push to buffer\n",
    "    human_json[str(len(human_json))] = sys_utterances\n",
    "\n",
    "# Preprocess\n",
    "human_json = align_prediction(human_json, kbret_ids)\n",
    "\n",
    "# Push to model buffer\n",
    "model_prediction_dict['Human'] = human_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract user goal\n",
    "gold_json = json.load(open('./CamRest676.json','r'))\n",
    "gen_kbret_json  = json.load(open('../runs/CAMREST_flattenKB_False_kbpercentage_KBret//gen_dialogue.json'))\n",
    "id_to_goal_dict, gold_dial =  extract_goal_from_gold(gold_json, gen_kbret_json, kbret_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure success rate\n",
    "KB = pd.DataFrame.from_records(json.load(open('../data/CamRest/KB.json','r')))\n",
    "KB = KB.fillna('0123456789876543210')\n",
    "KB = KB.applymap(preprocess_entity)\n",
    "\n",
    "data = []\n",
    "success_rate_data = []\n",
    "for model_name, predictions in model_prediction_dict.items():\n",
    "    for dial_id, prediction in predictions.items():\n",
    "        goal = id_to_goal_dict[dial_id]\n",
    "        \n",
    "        # Find all valid entities in KB\n",
    "        subset_KB = KB\n",
    "        constraints, request = goal['constraint'], goal['request']\n",
    "        for constraint in constraints:\n",
    "            constraint_value = preprocess_entity(constraint[1])\n",
    "            if constraint_value != 'dontcare':\n",
    "                subset_KB = subset_KB.loc[subset_KB[constraint[0]].str.contains(constraint_value),:]\n",
    "        entity_list = subset_KB.loc[:,request].values.tolist()\n",
    "        \n",
    "        # Find all terms\n",
    "        terms = []\n",
    "        for turn in prediction:\n",
    "            terms += list(map(preprocess_entity, turn['text'].split()))\n",
    "        terms = ''.join(terms)\n",
    "        \n",
    "        # Check success goal\n",
    "        success = 0\n",
    "        for i, entity_attributes in enumerate(entity_list):\n",
    "            num_attr = len(entity_attributes)\n",
    "            found_attr = 0\n",
    "            for j, entity_attribute in enumerate(entity_attributes):\n",
    "                if entity_attribute in terms:\n",
    "                    found_attr += 1\n",
    "                    \n",
    "            if found_attr == num_attr:\n",
    "                success = 1\n",
    "                break\n",
    "    \n",
    "        if success == 0 and model_name == 'Human':\n",
    "            data.append({'dial_id':dial_id, 'ent': entity_list, 'constraint':constraints, 'request':request, 'KB':subset_KB.copy(), 'success':success})\n",
    "            \n",
    "        # Push success goal data\n",
    "        success_rate_data.append({'model_name':model_name, 'dial_id':dial_id, 'success':success})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(success_rate_data)\n",
    "success_df = df.groupby('model_name')['success'].sum() / df['dial_id'].nunique() * 100\n",
    "success_df.to_csv('camrest_success_rate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "GPT2+KA0      30.379747\n",
       "GPT2+KA10     62.025316\n",
       "GPT2+KA100    72.151899\n",
       "GPT2+KA161    74.683544\n",
       "GPT2+KA50     70.886076\n",
       "GPT2+KB       62.025316\n",
       "Human         86.075949\n",
       "KBret         62.025316\n",
       "Name: success, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
